{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "boosting_and_optimisation.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ikikika/data_science/blob/ml_algorithms/boosting_and_optimisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49SPhcpcEz-6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "782fc274-b96e-422d-c599-e29261accd55"
      },
      "source": [
        "import pandas as pd\n",
        "dataset = pd.read_csv('https://raw.githubusercontent.com/ikikika/data_science/ml_algorithms/cancer.csv')\n",
        "\n",
        "dataset.head()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id diagnosis  ...  symmetry_worst  fractal_dimension_worst\n",
              "0    842302         M  ...          0.4601                  0.11890\n",
              "1    842517         M  ...          0.2750                  0.08902\n",
              "2  84300903         M  ...          0.3613                  0.08758\n",
              "3  84348301         M  ...          0.6638                  0.17300\n",
              "4  84358402         M  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-WXDIqjlzv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = dataset.iloc[:, 2:29].values\n",
        "y = dataset.iloc[:, 1].values # because we want to predict value for column[1], diagnosis"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ftn9L4fTIt9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIKtd6H2I59L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "8cd9cc8d-8400-4eea-e25b-6959c7eb9dd8"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.fit_transform(x_test)\n",
        "\n",
        "print(x_train)\n",
        "# note: sometimes, scaling doesnt help in accuracy"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.72427059 -0.02895552 -0.76061684 ... -0.45100338 -0.92152015\n",
            "  -0.93848301]\n",
            " [-0.8328743   1.81708623 -0.86727123 ... -1.7622065  -0.70381307\n",
            "  -0.79512206]\n",
            " [-0.14981409 -0.12855376 -0.1630202  ...  0.42399837  0.01178066\n",
            "  -0.38744691]\n",
            " ...\n",
            " [-1.24556843  0.03821538 -1.19138441 ...  1.00444508 -0.15481259\n",
            "  -0.04579007]\n",
            " [-0.9128981  -0.99714304 -0.91250598 ... -1.00545993 -0.3567438\n",
            "  -0.57152718]\n",
            " [-0.7957204   0.40186476 -0.78219671 ...  0.9957817  -0.54984052\n",
            "  -0.4741863 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQQT5a1rJSu1",
        "colab_type": "text"
      },
      "source": [
        "# Principle Component Analysis (PCA)\n",
        "* We have a lot of features\n",
        "* PCA will reduce the number of features\n",
        "* Similiar to linear regression\n",
        "* Linear regression: measure vertical distance to regression line\n",
        "* PCA: measure direct (perpendicular) distance to regression line\n",
        "* we can have x as scaler value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKWwoqb5JXRk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "854f7de8-29da-4aac-ee71-9835347c0e58"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components = 1) # take all feature in x and turn them into 1 single feature\n",
        "x_train_scaled = pca.fit_transform(x_train)\n",
        "print(x_train_scaled[:10])\n",
        "# from print(x_train), we have many different values from different features. \n",
        "# scaling them turns them into 1 feature "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1.03501952]\n",
            " [-1.98300081]\n",
            " [ 0.65951683]\n",
            " [-0.91504357]\n",
            " [-2.2373985 ]\n",
            " [-2.15130333]\n",
            " [-0.66304274]\n",
            " [-2.8651742 ]\n",
            " [-4.1235241 ]\n",
            " [-2.16701192]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyPwCb9PKGMf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "49c6daff-9699-4d0c-d1f5-797759106295"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(x_train_scaled, y_train)\n",
        "plt.show()\n",
        "# we see that the values from x~-2.5 to x~2.5, there are overlaps. \n",
        "# if the model is accurate, there should be no overlaps, as we assume 1 set of conditions will lead to 1 diagnosis, no possibility of have both diagnosises\n",
        "# model may not be accurate as features are reduced too much"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ln_k1-hr5DM",
        "colab_type": "text"
      },
      "source": [
        "# Gradient Boosting\n",
        "* Take a bunch of different models\n",
        "* Use something called gradient descent\n",
        "* Try to find the best model\n",
        "* Take different features from different tinier models\n",
        "* Combine them all together to form one massive very accurate model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5bxj2gWsAob",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "12ea9d2a-bec6-4df2-c438-404c7fa4bb2c"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gradientBoost = GradientBoostingClassifier()\n",
        "gradientBoost.fit(x_train, y_train)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
              "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
              "                           max_features=None, max_leaf_nodes=None,\n",
              "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                           min_samples_leaf=1, min_samples_split=2,\n",
              "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                           n_iter_no_change=None, presort='deprecated',\n",
              "                           random_state=None, subsample=1.0, tol=0.0001,\n",
              "                           validation_fraction=0.1, verbose=0,\n",
              "                           warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rau5XbqesSMz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5c557fc6-938d-4423-f102-61ff3dc56c37"
      },
      "source": [
        "y_predict = gradientBoost.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_test, y_predict))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[73  5]\n",
            " [ 1 35]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOF8kAzatCRb",
        "colab_type": "text"
      },
      "source": [
        "# Extreme Gradient Boosting (XGBoost)\n",
        "* Similiar to regular gradeint boosting\n",
        "* Has a couple of hyper-parameters adjusted\n",
        "\n",
        "**Wins more kaggle competitions**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq28ayLYteuc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "4691dee1-d75f-453b-9959-a953f90bbd18"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgboost = XGBClassifier()\n",
        "xgboost.fit(x_train, y_train)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9hdEKHotoq8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f13588f6-61ec-491d-cde3-9fc27557b959"
      },
      "source": [
        "y_predict = xgboost.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_test, y_predict))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[74  4]\n",
            " [ 1 35]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}